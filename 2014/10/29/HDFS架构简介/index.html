<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>HDFS架构简介(转载) | JiangNan&#39;s Blog</title>
  <meta name="author" content="JiangNan">
  
  <meta name="description" content="筚路蓝缕，以启山林">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="HDFS架构简介(转载)"/>
  <meta property="og:site_name" content="JiangNan&#39;s Blog"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="JiangNan&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  

</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">JiangNan&#39;s Blog</a></h1>
  <h2><a href="/">筚路蓝缕，以启山林</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">首页</a></li>
    
      <li><a href="/archives">归档</a></li>
    
      <li><a href="/about">关于我</a></li>
    
      <li><a href="/feature">规划页</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div></header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-10-29T08:24:49.000Z"><a href="/2014/10/29/HDFS架构简介/">Oct 29 2014</a></time>
      
      
  
    <h1 class="title">HDFS架构简介(转载)</h1>
  

    </header>
    <div class="entry">
      
        <h2 id="一-_HDFS框架简述">一. HDFS框架简述</h2><p><img src="/img/Hadoop/1.jpg" alt=""><br><a id="more"></a><br>HDFS设计目标:</p>
<ol>
<li>容错性</li>
<li>流式数据访问</li>
<li>大规模数据集</li>
<li>简单的一致性模型</li>
<li>移动计算到数据附近</li>
<li>可移植性</li>
</ol>
<h2 id="二-_HDFS分解简述">二. HDFS分解简述</h2><h3 id="NameNode_/_DataNode">NameNode / DataNode</h3><p>HDFS采用Master/Slave架构，HDFS集群是由一个NameNode和多个DataNodes组成。<span style="color:red">NameNode是中心服务器，负责管理文件系统的名字空间(namespace)以及客户端的访问。</span>DataNode负责管理它所在节点上的存储。用户能够通过HDFS文件系统的名字空间以文件的形式在上面存储数据。</p>
<p>对于内部存储，一个文件被切分为一个或多个块，存储在一组DataNode上。<span style="color:red">NameNode执行文件系统的名字空间操作</span>，比如打开、关闭、重命名文件或目录。它也负责确定数据块到具体DataNode节点的映射。</p>
<h3 id="数据存储副本容错">数据存储副本容错</h3><p>HDFS文件的所有数据块都会有副本。每个文件的数据块大小和副本系数都是可配置的。HDFS中的文件都是一次性写入的，并且在任何时候只能有一个写入者。<br><span style="color:red">NameNode全权管理数据块的复制</span>，它周期性地从集群中的每个DataNode接收心跳信号和块状态报告(Block Report)。块状态报告包含了一个该DataNode上所有数据块的列表。</p>
<p><img src="/img/Hadoop/2.jpg" alt=""></p>
<h3 id="副本放置策略">副本放置策略</h3><p>副本的放置策略是区分文件系统的重要特性之一，也是HDFS性能和可靠性的关键，HDFS采用了<span style="color:red"><strong>机架感知(rack-aware)的策略</strong></span>来存储副本。 文件写流程可以参考<a href="http://flyingdutchman.iteye.com/blog/1874713" target="_blank" rel="external">这里</a>  <a href="http://hpuxtbjvip0.blog.163.com/blog/static/367413132013314105119419/" target="_blank" rel="external">这里</a></p>
<p>在大多数情况下，副本系数是3，HDFS的存放策略是将一个副本存放在本地机架的节点上，一个副本放在同一机架的另一个节点上，最后一个副本放在不同机架的节点上。这种策略减少了机架间的数据传输，这就提高了写操作的效率。整个机架的错误远远比单个节点的错误少，所以这个策略不会影响到数据的可靠性和可用性。于此同时，因为数据块只放在两个（不是三个）不同的机架上，所以此策略减少了读取数据时需要的网络传输总带宽。在这种策略下，副本并不是均匀分布在不同的机架上。三分之一的副本在一个节点上，三分之二的副本在一个机架上，如果大于3个副本，其他副本均匀分布在剩下的机架中，这一策略在不损害数据可靠性和读取性能的情况下改进了写的性能。</p>
<h3 id="机架感知">机架感知</h3><p>一个大型集群大多会被分为多个机架(Rack)，一个机架包含多个节点，一般来说，机架内部机器的通信速度要高于机架之间的通信速度，而且往往机架之间的通信受到上层交换机等的带宽限制。</p>
<p>HDFS中，对机架的感知并非是自适应的，即机架的配置是由配置文件决定，并且是人工指定的，这些rackid信息可以通过topology.script.file.name配置，通过IP到机架id的映射指定哪些节点属于哪个机架，在NameNode启动时将配置信息读取到内存中，保存在一个map中。</p>
<p>通过机架感知，NameNode就可以画出DataNode以及交换机等节点的<span style="color:red">网络拓扑图</span>，通过拓扑图就可以计算出任意两个DataNode之间的距离，得到最优的存放策略，优化整个集群的网络带宽均衡以及数据最优分配。</p>
<h3 id="安全模式">安全模式</h3><p>安全模式是指NameNode的一种特殊状态。处于安全模式的NameNode是不进行数据块的复制的。NameNode从所有的 DataNode接收心跳信号和块状态报告。当Namenode检测确认某个数据块的副本数目达到该数据块的最小副本数，那么该数据块会被认为是副本安全(safely replicated)的。<br>Namenode退出安全模式状态后，它会确定哪些数据块的副本没有达到指定数目，并将这些数据块复制到其他DataNode上。</p>
<h3 id="元数据持久化">元数据持久化</h3><p>HDFS通过dfs.name.dir这个参数设置HDFS的元数据信息存放在NameNode本地操作系统的目录，目录里通常包括以下文件：edits 、FsImage、 FsTime、VERSION</p>
<h3 id="EditLog">EditLog</h3><p>Namenode用edits文件来保存对元数据进行的每次操作，比如创建文件，删除 文件，修改文件的副本系数。类似于mysql中的binlog机制。</p>
<p>###SecondNameNode </p>
<p>SecondNamenode其实只是一个简单的元数据备份 进程，它会定期（缺省是1小时）把edits文件的内容合并到fsimage文件，同时保存最新的元数据副本在SecondNamenode进程所在机器的文件系统里。</p>
<h3 id="FileImage">FileImage</h3><p>整个文件系统的名字空间，包括数据块到文件的映射、文件的属性等，都存储在FsImage的文件中，FsImage结合edits才能准确表示内存中的元数据信息。</p>
<p>当NameNode启动时，它从硬盘中读取Editlog和FsImage，将所有Editlog中的事务作用合并到内存中的FsImage上，并将这个新版本的FsImage从内存中保存到本地磁盘上，然后删除旧的Editlog，因为这个旧的Editlog的事务都已经作用在FsImage上了。这个过程称为一个检查点(checkpoint)，在当前实现中，检查点只发生在NameNode启动时，在不久的将来将实现支持周期性的检查点，此时这个时候系统处于安全模式，NameNode等待DataNode上报各自的block 数据块信息。</p>
<h3 id="Format_HDFS系统">Format  HDFS系统</h3><p>hadoop namenode -format命令用来初始化HDFS系统，事实就是初始化dfs.name.dir目录中的四个文件edits，FsImage，FsTime ，VERSION。</p>
<h3 id="故障容错">故障容错</h3><h3 id="DataNode数据复制">DataNode数据复制</h3><p>每个DataNode周期性地向NameNode发送心跳。网络割裂可能导致部分DataNode跟NameNode失去联系。NameNode将近期不发送心跳信号DataNode标记为宕机，不会再将新的IO请求发给它们。NameNode通过复制操作将新的副本复制到有效的DataNode。<br>在下列情况下，可能需要重新复制：某个DataNode节点失效，某个副本遭到损坏，DataNode上的硬盘错误，或者文件的副本系数增大。</p>
<h3 id="集群均衡">集群均衡</h3><p>HDFS的架构支持数据均衡策略。如果某个DataNode节点上的空闲空间低于特定的临界点，系统就会自动地将数据从该DataNode移动到其他DataNode。当对某个文件的请求突然增加，那么也可能启动一个计划创建该文件新的副本，并且同时重新平衡集群中的其他数据。这些均衡策略目前还没有实现。<br>数据完整性</p>
<p>HDFS客户端实现了对HDFS文件内容的校验和(checksum)检查。当客户端创建一个新的HDFS文件，会计算这个文件每个数据块的校验和，并将校验和作为一个单独的隐藏文件保存在同一个HDFS名字空间下。当客户端获取文件内容后，它会校验文件的完整性，如果数据错误，客户端可以选择从其他DataNode获取该数据块的副本。</p>
<h3 id="元数据错误">元数据错误</h3><p>FsImage和Editlog是HDFS的核心数据结构，如果损坏了，整个HDFS都将失效。因而，NameNode可以配置成支持维护多个FsImage和Editlog的副本。任何对FsImage或者Editlog的修改，都将同步到它们的副本上。这种多副本的同步操作可能会降低NameNode每秒处理的名字空间事务数量。然而这个代价是可以接受的，因为即使HDFS的应用是数据密集的，它们也非元数据密集的。当NameNode重启的时候，它会选取最近的完整的FsImage和Editlog来使用。</p>
<p>NameNode是HDFS集群中的单点故障(single point of failure)所在。如果NameNode机器故障，是需要手工干预的。目前，自动重启或在另一台机器上做NameNode故障转移的功能还没实现。</p>
<h3 id="快照">快照</h3><p>快照支持某一特定时刻的数据的复制备份。利用快照，可以让HDFS在数据损坏时恢复到过去一个已知正确的时间点。HDFS目前还不支持快照功能，但计划在将来的版本进行支持。</p>
<h3 id="数据模型">数据模型</h3><h3 id="数据分段">数据分段</h3><p>创建文件时以及写数据时，客户端的请求其实并没有立即发送给NameNode，事实上，HDFS客户端会先将文件数据缓存到本地的一个临时文件。写操作被透明地重定向到这个临时文，当临时文件的数据量超过一个数据块的大小，客户端才会联系NameNode。NameNode将文件名插入文件系统的层次结构中，并且分配一个数据块给它。然后返回DataNode的标识符和目标数据块给客户端。客户端再将数据从本地临时文件上传到指定的DataNode上。</p>
<p>当文件关闭时，在临时文件中没有上传的数据也会传输到指定的DataNode上，客户端会告诉NameNode文件已经关闭。此时NameNode才将文件创建操作提交到日志里进行存储。如果NameNode在文件关闭前宕机了，则该文件将丢失。</p>
<p>上述方法是对在HDFS上运行的目标应用进行认真考虑后得到的结果。这些应用需要进行文件的流式写入。如果不采用客户端缓存，由于网络速度和网络堵塞会对吞估量造成比较大的影响。</p>
<h3 id="流水线复制">流水线复制</h3><p>客户端向HDFS文件写入数据时，首先写入本地临时文件，假设该文件的副本系数为3，当本地临时文件累积到一个数据块的大小时，客户端会从NameNode获取一个DataNode列表用于存放副本，然后客户端向第一个DataNode传输数据，第一个DataNode一小部分一小部分(4 KB)地接收数据并写入本地仓库，并同时传输该部分到列表中第二个DataNode节点。第二个DataNode接收数据，并同时传给第三个DataNode。因此，DataNode能流水线式地从前一个节点接收数据，并在同时转发给下一个节点，数据以流水线的方式从前一个DataNode复制到下一个</p>
<h3 id="简单一致性模型">简单一致性模型</h3><p>HDFS主要应用于大规模的数据处理，一个数据集通常由数据源生成或复制，在此基础上进行各种分析。每个分析至少都会涉及数据集中的大部分数据 (甚至全部)，因此读取整个数据集的时间比读取第一条记录的延迟更为重要。</p>
<p>因此HDFS对文件操作需要的是一次写入，多次读取的。一个文件一旦创建、写入、关闭之后就不需要修改了。这个假定简化了数据一致的问题和高吞吐量的数据访问。文件的修改、写操作只能append（），在文件的末尾增加，它不支持在文件的任意位置修改。</p>
<p>转载自： <a href="http://asyty-cp.blog.163.com/blog/static/117542439201191322858356/" target="_blank" rel="external">http://asyty-cp.blog.163.com/blog/static/117542439201191322858356/</a></p>

      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/categories/转载/">转载</a>
  </div>

        
  
  <div class="tags">
    <a href="/tags/Hadoop/">Hadoop</a>
  </div>

        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


	
	<nav id="pagination" >
    
    <a href="/2014/10/29/Java-多线程-二/" class="alignleft prev" >上一页</a>
    
    
    <a href="/2014/10/28/Java-多线程-一/" class="alignright next" >下一页</a>
    
    <div class="clearfix"></div>
	</nav>

<section id="comment">
<div class="ds-thread" data-thread-key="/2014/10/29/HDFS架构简介/" data-title="HDFS架构简介(转载)" data-url="http://jiangnan31.github.io/2014/10/29/HDFS架构简介/"></div>
  <script type="text/javascript">
	var duoshuoQuery = {short_name:"jiangnan31"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:jiangnan31.github.io">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">分类</h3>
  <ul class="entry">
  
    <li><a href="/categories/Code/">Code</a><small>1</small></li>
  
    <li><a href="/categories/扯犊子/">扯犊子</a><small>2</small></li>
  
    <li><a href="/categories/笔记/">笔记</a><small>4</small></li>
  
    <li><a href="/categories/转载/">转载</a><small>12</small></li>
  
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">标签</h3>
  <ul class="entry">
  
    <li><a href="/tags/Concurrency/">Concurrency</a><small>9</small></li>
  
    <li><a href="/tags/Distributed/">Distributed</a><small>1</small></li>
  
    <li><a href="/tags/Hadoop/">Hadoop</a><small>2</small></li>
  
    <li><a href="/tags/JavaScript/">JavaScript</a><small>1</small></li>
  
    <li><a href="/tags/LeetCode/">LeetCode</a><small>1</small></li>
  
    <li><a href="/tags/Linux/">Linux</a><small>2</small></li>
  
    <li><a href="/tags/RPC/">RPC</a><small>1</small></li>
  
    <li><a href="/tags/Regex/">Regex</a><small>1</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2015 JiangNan
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>